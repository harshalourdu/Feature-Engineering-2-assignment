{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is the Filter method in feature selection, and how does it work?\n",
    "\n",
    "Q2. How does the Wrapper method differ from the Filter method in feature selection?\n",
    "\n",
    "Q3. What are some common techniques used in Embedded feature selection methods?\n",
    "\n",
    "Q4. What are some drawbacks of using the Filter method for feature selection?\n",
    "\n",
    "Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature\n",
    "selection?\n",
    "\n",
    "Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn.\n",
    "You are unsure of which features to include in the model because the dataset contains several different\n",
    "ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method.\n",
    "\n",
    "Q7. You are working on a project to predict the outcome of a soccer match. You have a large dataset with\n",
    "many features, including player statistics and team rankings. Explain how you would use the Embedded\n",
    "method to select the most relevant features for the model.\n",
    "\n",
    "Q8. You are working on a project to predict the price of a house based on its features, such as size, location,\n",
    "and age. You have a limited number of features, and you want to ensure that you select the most important\n",
    "ones for the model. Explain how you would use the Wrapper method to select the best set of features for the\n",
    "predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: What is the Filter method in feature selection, and how does it work?\n",
    "The Filter method in feature selection is a technique that assesses the importance of each feature independently of the machine learning model. It involves ranking features based on their statistical properties and selecting the most relevant ones. These features are evaluated through various criteria such as correlation, mutual information, chi-square tests, or other statistical measures.\n",
    "\n",
    "How it works:\n",
    "It ranks the features based on certain criteria (like correlation with the target variable).\n",
    "It selects a subset of features that are highly correlated with the target or have strong statistical significance.\n",
    "The Filter method is computationally inexpensive since it does not involve training a model for each subset of features.\n",
    "Common techniques include:\n",
    "\n",
    "Correlation-based Feature Selection: Features are evaluated based on correlation with the target variable.\n",
    "Chi-Square Test: Used for categorical features to test if there is a significant relationship between the feature and the target.\n",
    "ANOVA F-Test: Used to evaluate the variance between feature classes.\n",
    "\n",
    "\n",
    "# Q2: How does the Wrapper method differ from the Filter method in feature selection?\n",
    "The Wrapper method evaluates feature subsets by using the performance of a predictive model to assess the feature set's quality. Unlike the Filter method, which considers features independently, the Wrapper method evaluates the feature subset as a whole. It requires training and evaluating the model multiple times with different combinations of features.\n",
    "\n",
    "How it works:\n",
    "It uses a search algorithm (such as forward selection, backward elimination, or genetic algorithms) to explore different subsets of features.\n",
    "It evaluates each subset using a specific machine learning model (like SVM, Random Forest, etc.) and selects the one with the best performance (often using cross-validation).\n",
    "It is more computationally expensive than the Filter method since it requires training the model for each subset.\n",
    "Differences:\n",
    "\n",
    "Filter method: Evaluates features individually without using a machine learning model.\n",
    "Wrapper method: Evaluates feature subsets as a whole, using model performance to decide the best feature set.\n",
    "\n",
    "\n",
    "# Q3: What are some common techniques used in Embedded feature selection methods?\n",
    "Embedded methods perform feature selection during the model training process, meaning the feature selection process is integrated within the model training algorithm itself. These methods evaluate the relevance of features based on the model's internal parameters.\n",
    "\n",
    "Common techniques in embedded methods:\n",
    "\n",
    "Lasso (L1 Regularization): Lasso regression adds a penalty term (L1 regularization) that shrinks coefficients of less important features to zero. Features with non-zero coefficients are selected.\n",
    "Ridge (L2 Regularization): Ridge regression applies L2 regularization, which penalizes large coefficients, but unlike Lasso, it does not shrink them to zero. However, it can still help reduce the impact of less important features.\n",
    "Decision Trees and Random Forests: Decision tree-based models (like Random Forests) can rank features based on their importance, measured by how much they reduce impurity in the tree.\n",
    "Gradient Boosting Machines (GBM): Similar to Random Forest, GBM can also provide feature importances during model training.\n",
    "Recursive Feature Elimination (RFE): RFE recursively removes the least important features based on model performance, ranking features and selecting the most relevant ones.\n",
    "\n",
    "\n",
    "# Q4: What are some drawbacks of using the Filter method for feature selection?\n",
    "The Filter method has several drawbacks:\n",
    "\n",
    "Ignoring Feature Interactions: It evaluates features independently of each other, so it may overlook interactions between features that could be important for the model.\n",
    "Suboptimal Feature Subsets: Since the method does not consider the full feature set together, it can select features that are not optimal when combined, leading to suboptimal model performance.\n",
    "No Model Consideration: Since the Filter method doesnâ€™t take into account how the features perform in a specific model, it may select irrelevant features or miss important ones that are only useful in the context of a model.\n",
    "Limited to Statistical Measures: It depends only on statistical methods like correlation or mutual information, which might not capture all the nuances in data.\n",
    "\n",
    "\n",
    "# Q5: In which situations would you prefer using the Filter method over the Wrapper method for feature selection?\n",
    "The Filter method is preferable over the Wrapper method in the following situations:\n",
    "\n",
    "Large Datasets: When working with datasets that have a large number of features, the Filter method is more efficient because it does not require training a model for each feature subset.\n",
    "Computational Efficiency: If computational resources are limited or when you need a quick feature selection method, the Filter method is generally faster as it avoids iterative training.\n",
    "Preprocessing Step: The Filter method is useful for initial feature selection, as it provides a quick way to remove irrelevant features before applying more complex models or methods.\n",
    "When Feature Interactions Are Not Critical: If interactions between features are not crucial to model performance, the Filter method can still provide useful feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6: In a telecom company, you are working on a project to develop a predictive model for customer churn. You are unsure of which features to include in the model because the dataset contains several different ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Example\n",
    "X = df.drop('Churn', axis=1)  # Features\n",
    "y = df['Churn']  # Target\n",
    "\n",
    "# SelectKBest with Chi-square test for feature selection\n",
    "selector = SelectKBest(score_func=chi2, k='all')\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Get feature ranking\n",
    "feature_scores = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Score': selector.scores_\n",
    "})\n",
    "print(feature_scores.sort_values(by='Score', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7: You are working on a project to predict the outcome of a soccer match. You have a large dataset with many features, including player statistics and team rankings. Explain how you would use the Embedded method to select the most relevant features for the model.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df contains your dataset\n",
    "X = df.drop('Outcome', axis=1)  # Features\n",
    "y = df['Outcome']  # Target\n",
    "\n",
    "# Train Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get feature importance scores\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "})\n",
    "\n",
    "# Sort and display most important features\n",
    "print(feature_importances.sort_values(by='Importance', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8: You are working on a project to predict the price of a house based on its features, such as size, location, and age. You have a limited number of features, and you want to ensure that you select the most important ones for the model. Explain how you would use the Wrapper method to select the best set of features for the predictor.\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Assuming df contains the features and target\n",
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']\n",
    "\n",
    "# Use Linear Regression model for feature selection\n",
    "model = LinearRegression()\n",
    "selector = RFE(model, n_features_to_select=5)  # Select top 5 features\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Get selected features\n",
    "selected_features = X.columns[selector.support_]\n",
    "print(selected_features)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
